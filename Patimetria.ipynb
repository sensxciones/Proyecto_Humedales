{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Patimetria2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOiiSGq949DYotMFYz9I4x7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mar3334/Patimetria/blob/main/Patimetria2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IsugSfCY_zE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "472a4d44-5ed8-4c89-9be9-58bdea27cc84"
      },
      "source": [
        "from google.colab import drive #Se importa el drive donde estan todos los .py y las imagenes utilizadas, esta celda debe ser modificada en caso de que se quiera probar el codigo en otro equipo\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xh-5LoycHuly",
        "outputId": "81f637f5-4342-4056-81c8-cab2f2976bbc"
      },
      "source": [
        "!pip install torch==1.4.0 torchvision==0.5.0 #Se instala la version de torch y torchvision necesaria para poder usar el codigo."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4MB 20kB/s \n",
            "\u001b[?25hCollecting torchvision==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/90/6141bf41f5655c78e24f40f710fdd4f8a8aff6c8b7c6f0328240f649bdbe/torchvision-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 32.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.19.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.15.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "  Found existing installation: torchvision 0.8.1+cu101\n",
            "    Uninstalling torchvision-0.8.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.8.1+cu101\n",
            "Successfully installed torch-1.4.0 torchvision-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eppi8CjtPagb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8afaf444-b138-48c3-e810-fe933e68898a"
      },
      "source": [
        "!cp -rf /content/drive/MyDrive/siamese-triplet /content/drive/MyDrive/siamese-triplet #Se copia en el drive cualquier cambio que se realize a los .py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot copy a directory, '/content/drive/MyDrive/siamese-triplet', into itself, '/content/drive/MyDrive/siamese-triplet/siamese-triplet'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB-oh40GYmf8"
      },
      "source": [
        "# Se importar todos los modulos y funciones necesarios\r\n",
        "import numpy as np\r\n",
        "import matplotlib\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import torch\r\n",
        "from torch.optim import lr_scheduler\r\n",
        "import torch.optim as optim\r\n",
        "from torch.autograd import Variable\r\n",
        "from torchvision import models, transforms\r\n",
        "from PIL import Image\r\n",
        "import sys\r\n",
        "sys.path.append('/content/drive/MyDrive/siamese-triplet')\r\n",
        "\r\n",
        "#La siguiente importacion es de un codigo diseñado para el proyecto patimetria:\r\n",
        "from duckies_dataset import DuckieDataset, Rescale\r\n",
        "#Los siguientes modulos son versiones modificadas de .py de terceros adapatados para utilizar en el proyecto patimetria:\r\n",
        "from networks import VGGEmbeddingNet, EmbeddingNet, TripletNet\r\n",
        "from trainer import fit, train_epoch, test_epoch\r\n",
        "from datasets import TripletMNIST\r\n",
        "from losses import TripletLoss"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-clKeEwY1Ot"
      },
      "source": [
        "vgg_model = VGGEmbeddingNet()\r\n",
        "emb_net = EmbeddingNet()"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLOX2DaaY-_Z"
      },
      "source": [
        "# Se define una transformacion que convierte las imagenes a tensores de tamaño [224, 224]\r\n",
        "trans = transforms.Compose([Rescale(224),\r\n",
        "                            transforms.ToTensor()])"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld4nhSBNZmy8"
      },
      "source": [
        "# Se definen los datasets de entrenamiento y de testeo.\r\n",
        "train_dataset = DuckieDataset(\"/content/drive/MyDrive/train\", transform= trans)\r\n",
        "test_dataset = DuckieDataset(\"/content/drive/MyDrive/train\", train=False, transform= trans)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn2gkk-saRZq",
        "outputId": "ae7be777-2cf7-4c6f-d62f-7fd5f984ce37"
      },
      "source": [
        "cuda = torch.cuda.is_available()\r\n",
        "%matplotlib inline\r\n",
        "# Set up data loaders\r\n",
        "\r\n",
        "triplet_train_dataset = TripletMNIST(train_dataset) # Returns triplets of images\r\n",
        "triplet_test_dataset = TripletMNIST(test_dataset)\r\n",
        "batch_size = 32\r\n",
        "kwargs = {'num_workers': 8, 'pin_memory': True} if cuda else {}\r\n",
        "triplet_train_loader = torch.utils.data.DataLoader(triplet_train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\r\n",
        "triplet_test_loader = torch.utils.data.DataLoader(triplet_test_dataset, batch_size=batch_size, shuffle=False, **kwargs)\r\n",
        "\r\n",
        "# Set up the network and training parameters\r\n",
        "\r\n",
        "margin = 1.\r\n",
        "embedding_net = EmbeddingNet()\r\n",
        "model = TripletNet(vgg_model)\r\n",
        "if cuda:\r\n",
        "    model.cuda()\r\n",
        "loss_fn = TripletLoss(margin)\r\n",
        "lr = 1e-3\r\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\r\n",
        "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\r\n",
        "n_epochs = 10\r\n",
        "log_interval = 500"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk7ukB4ga3RO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96fc1d62-f552-468d-b41e-79ace439f384"
      },
      "source": [
        "fit(triplet_train_loader, triplet_test_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval) #Se empieza a entrenar la red."
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: [0/1080 (0%)]\tLoss: 0.830724\n",
            "Epoch: 1/10. Train set: Average loss: 0.8479\n",
            "Epoch: 1/10. Validation set: Average loss: 0.6013\n",
            "Train: [0/1080 (0%)]\tLoss: 0.598962\n",
            "Epoch: 2/10. Train set: Average loss: 0.6066\n",
            "Epoch: 2/10. Validation set: Average loss: 0.4509\n",
            "Train: [0/1080 (0%)]\tLoss: 0.527424\n",
            "Epoch: 3/10. Train set: Average loss: 0.4815\n",
            "Epoch: 3/10. Validation set: Average loss: 0.4094\n",
            "Train: [0/1080 (0%)]\tLoss: 0.384951\n",
            "Epoch: 4/10. Train set: Average loss: 0.4150\n",
            "Epoch: 4/10. Validation set: Average loss: 0.4150\n",
            "Train: [0/1080 (0%)]\tLoss: 0.385009\n",
            "Epoch: 5/10. Train set: Average loss: 0.4055\n",
            "Epoch: 5/10. Validation set: Average loss: 0.3703\n",
            "Train: [0/1080 (0%)]\tLoss: 0.332187\n",
            "Epoch: 6/10. Train set: Average loss: 0.4325\n",
            "Epoch: 6/10. Validation set: Average loss: 0.4115\n",
            "Train: [0/1080 (0%)]\tLoss: 0.353259\n",
            "Epoch: 7/10. Train set: Average loss: 0.4608\n",
            "Epoch: 7/10. Validation set: Average loss: 0.3817\n",
            "Train: [0/1080 (0%)]\tLoss: 0.496955\n",
            "Epoch: 8/10. Train set: Average loss: 0.3890\n",
            "Epoch: 8/10. Validation set: Average loss: 0.3769\n",
            "Train: [0/1080 (0%)]\tLoss: 0.432635\n",
            "Epoch: 9/10. Train set: Average loss: 0.3811\n",
            "Epoch: 9/10. Validation set: Average loss: 0.3740\n",
            "Train: [0/1080 (0%)]\tLoss: 0.373952\n",
            "Epoch: 10/10. Train set: Average loss: 0.3820\n",
            "Epoch: 10/10. Validation set: Average loss: 0.3748\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OF26aefvTNlk"
      },
      "source": [
        "# Define functions to extract embeddings using diferent datasets\r\n",
        "def extract_embeddings(dataset, model, dims = 1024, opt = None):\r\n",
        "    with torch.no_grad():\r\n",
        "        model.eval()\r\n",
        "        embeddings = np.zeros((len(dataset), dims))\r\n",
        "        labels = list()\r\n",
        "        for k, it_ in enumerate(dataset):\r\n",
        "            images = it_[0].unsqueeze_(0)\r\n",
        "            images = images.cuda()\r\n",
        "            target = it_[1]\r\n",
        "            if opt is None:\r\n",
        "                aux = model.get_embedding(images).data.cpu().numpy()\r\n",
        "            else:\r\n",
        "                aux = model.get_embedding(images, opt).data.cpu().numpy()\r\n",
        "            embeddings[k] = aux.reshape(1, dims)\r\n",
        "            labels.append(target)\r\n",
        "    return embeddings, labels\r\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGORG9c1Twos"
      },
      "source": [
        "embeddings, labels = extract_embeddings(test_dataset, vgg_model, dims = 512)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUfuE4B2pnlI"
      },
      "source": [
        "#n_closest_images: (str), (int) ---> list\r\n",
        "# Funcion que recibe la ruta de una imagen y de manera opcional un numero entero\"n\" (por defecto 5), que escribe 3 listas y entrega 1:\r\n",
        "# Near_list: lista que contiene las n distancias mas cortas con respecto a la imagen entregada\r\n",
        "# List_labels: lista que contiene las etiquetas correspondientes a las \"n\" imagenes con distancias mas cortas. Esta lista es entregada por la funcion.\r\n",
        "# Label_ubication_list: lista que entrega la posicion de las \"n\" imagenes mas cercanas con respecto a su etiqueta.\r\n",
        "\r\n",
        "def n_closest_images(image, n=5):\r\n",
        "  img = Image.open(image).convert('RGB')\r\n",
        "  img = trans(img)\r\n",
        "  emb_img = vgg_model(img.unsqueeze(0).cuda())\r\n",
        "  embedding_img = emb_img.data.cpu().numpy()\r\n",
        "  list_dist, list_labels, neat_list, label_ubication_list = [], [], [], []\r\n",
        "  for i in range(embeddings.shape[0]):\r\n",
        "    emb2 = embeddings[i,:]\r\n",
        "    dist = np.sum((emb2 - embedding_img)**2)\r\n",
        "    list_dist.append(dist)\r\n",
        "  neat_list[:] = list_dist\r\n",
        "  neat_list.sort()\r\n",
        "  for i in range(n):\r\n",
        "    position = list_dist.index(neat_list[i])\r\n",
        "    label_ubication = position - labels.index(labels[position])\r\n",
        "    label_ubication_list.append(label_ubication)\r\n",
        "    list_labels.append(labels[position])\r\n",
        "  print (neat_list[:n], list_labels, label_ubication_list)\r\n",
        "  return list_labels"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYZvv4tkMwgC",
        "outputId": "cc0c51bb-de51-46e9-fadf-f08ba3f7aafd"
      },
      "source": [
        "n_closest_images(\"/content/drive/MyDrive/train/unclesam/unclesamrubberduckback400x400.jpg\")[0]"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0, 0.060384943114031024, 0.10958801921959464, 0.1299177350882725, 0.1657605146418235] [tensor(281.), tensor(233.), tensor(279.), tensor(259.), tensor(233.)] [0, 0, 2, 1, 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(281.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLrMbPxjb5fr"
      },
      "source": [
        "# closest_image_after_rotation: (str) ---> list\r\n",
        "# Funcion que recibe la ruta de una imagen, escribe 3 numeros y entrega 1:\r\n",
        "# neat_list[:1]: Corresponde a la distancia mas corta entre la imagen entregada y una del dataset\r\n",
        "# list_labels: Corresponde a la lista con las etiquetas de las imagenes del dataset, ordenadas desde las imagenes mas cercanas hasta las mas alejadas con respecto a la imagen entregada.\r\n",
        "# esta lista es entregada por la funcion.\r\n",
        "# Label_ubication_list: lista que entrega la posicion de las imagenes con respecto a su etiqueta. (Nota: si en la etiqueta tiene \"n\" imagenes, 0 representa la primera imagen y\r\n",
        "# \"k\" representa la \"k+1\"-esima imagen)\"\r\n",
        "def closest_image_after_rotation(image):\r\n",
        "  img = Image.open(image).convert('RGB')\r\n",
        "  flip = transforms.RandomHorizontalFlip(p=1)\r\n",
        "  img = flip(img)\r\n",
        "  img = trans(img)\r\n",
        "  emb_img = vgg_model(img.unsqueeze(0).cuda())\r\n",
        "  embedding_img = emb_img.data.cpu().numpy()\r\n",
        "  list_dist, list_labels, neat_list, label_ubication_list = [], [], [], []\r\n",
        "  for i in range(embeddings.shape[0]):\r\n",
        "    emb2 = embeddings[i,:]\r\n",
        "    dist = np.sum((emb2 - embedding_img)**2)\r\n",
        "    list_dist.append(dist)\r\n",
        "  neat_list[:] = list_dist\r\n",
        "  neat_list.sort()\r\n",
        "  for i in range(1):\r\n",
        "    position = list_dist.index(neat_list[i])\r\n",
        "    label_ubication = position - labels.index(labels[position])\r\n",
        "    label_ubication_list.append(label_ubication)\r\n",
        "    list_labels.append(labels[position])\r\n",
        "  print (neat_list[:1], list_labels, label_ubication_list)\r\n",
        "  return list_labels"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ2vTN9wLlwv"
      },
      "source": [
        "# percentage_check (dataset) ---> ()\r\n",
        "# Funcion que recibe un dataset y rota las imagenes del mismo para luego pasarlas por la red y verificar cuantas imagenes son clasificadas correctamente en su etiqueta.\r\n",
        "# El resultado es escrito como un porcentaje\r\n",
        "def percentage_check(dataset):\r\n",
        "  Right = 0\r\n",
        "  for i in range(len(dataset.data)):\r\n",
        "    img = dataset.data[i]\r\n",
        "    label= closest_image_after_rotation(img)\r\n",
        "    if label[0] == dataset.targets[i]:\r\n",
        "      Right += 1 \r\n",
        "  Total = len(dataset.targets)\r\n",
        "  Percentage = 100.0*Right/Total\r\n",
        "  print (\"% \" + str(Percentage) +\" de las imagenes fueron clasificadas correctamente.\")\r\n",
        "\r\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtNi2lfKRodR",
        "outputId": "4ade1391-659d-48ad-cb56-405011d23e1d"
      },
      "source": [
        "percentage_check(test_dataset)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.014830298870920092] [tensor(228.)] [0]\n",
            "[0.000790562431976653] [tensor(228.)] [1]\n",
            "[0.0005347803744119539] [tensor(229.)] [0]\n",
            "[0.0002853057729776891] [tensor(229.)] [1]\n",
            "[0.005259248510410241] [tensor(229.)] [3]\n",
            "[0.013021183815922278] [tensor(229.)] [3]\n",
            "[0.0015105033794725058] [tensor(230.)] [0]\n",
            "[0.0011089101533503347] [tensor(242.)] [1]\n",
            "[0.0001676862191677187] [tensor(253.)] [0]\n",
            "[0.0008023154293226153] [tensor(242.)] [1]\n",
            "[0.0021497095523895873] [tensor(231.)] [0]\n",
            "[0.026858760730506075] [tensor(238.)] [0]\n",
            "[0.00762641719461795] [tensor(231.)] [2]\n",
            "[7.534106779847337e-05] [tensor(232.)] [0]\n",
            "[5.165396724945656e-09] [tensor(232.)] [1]\n",
            "[0.0016120281162867835] [tensor(232.)] [2]\n",
            "[2.583180997155305e-06] [tensor(232.)] [4]\n",
            "[3.209828832736726e-06] [tensor(232.)] [3]\n",
            "[0.005567425441621343] [tensor(233.)] [1]\n",
            "[0.0011806258730058673] [tensor(233.)] [1]\n",
            "[0.0016295508976897006] [tensor(235.)] [0]\n",
            "[8.233695139201377e-05] [tensor(233.)] [3]\n",
            "[0.00013855297733366426] [tensor(234.)] [0]\n",
            "[0.011449900359762854] [tensor(282.)] [0]\n",
            "[0.0020510797863140954] [tensor(234.)] [2]\n",
            "[0.010192846490316817] [tensor(240.)] [0]\n",
            "[0.005798764142298289] [tensor(235.)] [0]\n",
            "[5.032481745845393e-08] [tensor(235.)] [1]\n",
            "[4.912543423615632e-07] [tensor(236.)] [0]\n",
            "[1.274621726943964e-07] [tensor(236.)] [1]\n",
            "[5.194306485883362e-09] [tensor(236.)] [0]\n",
            "[2.921745062177137e-06] [tensor(236.)] [0]\n",
            "[0.00010337527903695818] [tensor(254.)] [1]\n",
            "[1.551515863289354e-06] [tensor(236.)] [0]\n",
            "[0.01243543982976382] [tensor(237.)] [0]\n",
            "[0.09798514066844635] [tensor(237.)] [1]\n",
            "[0.0016778310848193883] [tensor(237.)] [2]\n",
            "[0.027847627075000495] [tensor(237.)] [3]\n",
            "[0.0028570279951117376] [tensor(237.)] [5]\n",
            "[0.03136742771897669] [tensor(237.)] [4]\n",
            "[0.028943036200444118] [tensor(278.)] [0]\n",
            "[0.030444750370862098] [tensor(278.)] [0]\n",
            "[0.001716229171982561] [tensor(238.)] [2]\n",
            "[5.8515536524656806e-05] [tensor(238.)] [3]\n",
            "[0.03619904614722388] [tensor(241.)] [3]\n",
            "[1.0733022157790692e-05] [tensor(252.)] [2]\n",
            "[0.00014135914862199164] [tensor(239.)] [1]\n",
            "[2.2230496689421775e-06] [tensor(239.)] [2]\n",
            "[0.0004367377139877667] [tensor(239.)] [3]\n",
            "[9.626215119565633e-07] [tensor(239.)] [0]\n",
            "[0.00049175607274371] [tensor(239.)] [5]\n",
            "[0.0007319033528953865] [tensor(240.)] [0]\n",
            "[6.838055517219732e-07] [tensor(240.)] [1]\n",
            "[1.996530393811051e-07] [tensor(240.)] [2]\n",
            "[1.3233351781154337e-06] [tensor(240.)] [3]\n",
            "[0.0007507586046177953] [tensor(241.)] [0]\n",
            "[0.0007507586046177953] [tensor(241.)] [0]\n",
            "[0.00041389903646944564] [tensor(241.)] [2]\n",
            "[0.012445919213563226] [tensor(241.)] [3]\n",
            "[0.029359023086704926] [tensor(241.)] [4]\n",
            "[0.0006765206601855131] [tensor(241.)] [5]\n",
            "[0.000909877068742844] [tensor(241.)] [10]\n",
            "[0.0012386208991124708] [tensor(241.)] [5]\n",
            "[0.04271848625802999] [tensor(241.)] [8]\n",
            "[0.006292864085475677] [tensor(241.)] [8]\n",
            "[0.0006567735734610446] [tensor(241.)] [0]\n",
            "[0.008038493923663723] [tensor(242.)] [0]\n",
            "[0.0019157315483539997] [tensor(270.)] [0]\n",
            "[0.015105961545054978] [tensor(242.)] [2]\n",
            "[0.02095703725981053] [tensor(273.)] [2]\n",
            "[0.017012127732088825] [tensor(242.)] [4]\n",
            "[0.0001281397056326879] [tensor(243.)] [0]\n",
            "[0.0001281397056326879] [tensor(243.)] [0]\n",
            "[0.021281356814147608] [tensor(243.)] [2]\n",
            "[0.021281356814147608] [tensor(243.)] [2]\n",
            "[0.005787238661155139] [tensor(243.)] [4]\n",
            "[0.005787238661155139] [tensor(243.)] [4]\n",
            "[0.003314405823069212] [tensor(243.)] [6]\n",
            "[0.003314405823069212] [tensor(243.)] [6]\n",
            "[0.0011484291891559065] [tensor(244.)] [0]\n",
            "[0.015499390582533065] [tensor(244.)] [0]\n",
            "[0.0027712713025042583] [tensor(244.)] [2]\n",
            "[0.003621157051062275] [tensor(267.)] [1]\n",
            "[0.027927686701181852] [tensor(257.)] [0]\n",
            "[0.0032315055392544622] [tensor(245.)] [0]\n",
            "[0.00048224285200688325] [tensor(245.)] [1]\n",
            "[0.02008414386341942] [tensor(245.)] [2]\n",
            "[0.03060236870517357] [tensor(249.)] [1]\n",
            "[0.03895667029476898] [tensor(276.)] [0]\n",
            "[0.011448969434378876] [tensor(283.)] [2]\n",
            "[0.036879582527317656] [tensor(246.)] [3]\n",
            "[0.00010147734236518043] [tensor(246.)] [4]\n",
            "[0.0028917732527575647] [tensor(246.)] [5]\n",
            "[0.027661450195938957] [tensor(242.)] [3]\n",
            "[0.011273431161456337] [tensor(283.)] [1]\n",
            "[0.010411719954440908] [tensor(246.)] [9]\n",
            "[0.0116931168525044] [tensor(246.)] [9]\n",
            "[1.9796309244590457e-06] [tensor(247.)] [0]\n",
            "[5.185512459520997e-06] [tensor(247.)] [3]\n",
            "[8.696438250653007e-05] [tensor(252.)] [3]\n",
            "[8.171279086264261e-06] [tensor(247.)] [1]\n",
            "[0.025316142789902425] [tensor(248.)] [1]\n",
            "[0.0005591900164200094] [tensor(248.)] [0]\n",
            "[0.0025782602734402728] [tensor(281.)] [3]\n",
            "[0.0017010279025258617] [tensor(242.)] [1]\n",
            "[0.001886974876438366] [tensor(249.)] [0]\n",
            "[0.003637953262221439] [tensor(249.)] [1]\n",
            "[0.019697875852027646] [tensor(249.)] [0]\n",
            "[0.042342353359616156] [tensor(244.)] [0]\n",
            "[0.033860494987595406] [tensor(250.)] [1]\n",
            "[0.0358200291972476] [tensor(250.)] [1]\n",
            "[9.38711542599613e-05] [tensor(250.)] [2]\n",
            "[0.019884023619399067] [tensor(250.)] [4]\n",
            "[7.836386317827682e-05] [tensor(250.)] [4]\n",
            "[0.00035293866519421364] [tensor(251.)] [0]\n",
            "[0.003289534267309095] [tensor(251.)] [1]\n",
            "[0.0013842117565743164] [tensor(251.)] [2]\n",
            "[0.0039933413215410595] [tensor(251.)] [3]\n",
            "[0.06591200775127214] [tensor(252.)] [1]\n",
            "[0.06497238389035062] [tensor(252.)] [1]\n",
            "[1.006763173229714e-06] [tensor(252.)] [2]\n",
            "[4.8846834300058685e-06] [tensor(252.)] [5]\n",
            "[1.4421159334603186e-06] [tensor(252.)] [4]\n",
            "[9.320422348085245e-06] [tensor(247.)] [0]\n",
            "[0.0003914993912861222] [tensor(268.)] [0]\n",
            "[0.0009869396824700523] [tensor(230.)] [1]\n",
            "[0.00019478331622327027] [tensor(268.)] [0]\n",
            "[0.01170169459546001] [tensor(242.)] [0]\n",
            "[0.0004032312955165874] [tensor(254.)] [0]\n",
            "[0.00014234503782196913] [tensor(254.)] [3]\n",
            "[0.007069370028005759] [tensor(254.)] [0]\n",
            "[0.0002858647167710065] [tensor(236.)] [2]\n",
            "[3.1156593511432774e-05] [tensor(255.)] [0]\n",
            "[0.0005581403839636937] [tensor(267.)] [0]\n",
            "[0.0007557703758971912] [tensor(267.)] [0]\n",
            "[0.003136024523753828] [tensor(265.)] [1]\n",
            "[0.005577566650202614] [tensor(256.)] [0]\n",
            "[0.001032173071391441] [tensor(256.)] [1]\n",
            "[0.018646860455466416] [tensor(256.)] [2]\n",
            "[0.02203085925935076] [tensor(256.)] [3]\n",
            "[0.013370867173291832] [tensor(257.)] [0]\n",
            "[0.005644875100884105] [tensor(257.)] [1]\n",
            "[0.002219411630135684] [tensor(257.)] [3]\n",
            "[0.0027398940795428117] [tensor(257.)] [2]\n",
            "[0.0073583773666605935] [tensor(242.)] [4]\n",
            "[0.012872400543200022] [tensor(258.)] [1]\n",
            "[0.008072219305724486] [tensor(258.)] [3]\n",
            "[0.0040971162090467994] [tensor(258.)] [2]\n",
            "[0.0076645597135891145] [tensor(259.)] [0]\n",
            "[0.05168674912826198] [tensor(284.)] [2]\n",
            "[0.002463086033183852] [tensor(270.)] [3]\n",
            "[0.0032388526004965487] [tensor(270.)] [0]\n",
            "[0.001279210845793472] [tensor(260.)] [0]\n",
            "[0.005190454774709483] [tensor(260.)] [1]\n",
            "[0.018322275945395407] [tensor(261.)] [3]\n",
            "[0.0005436346743195605] [tensor(261.)] [0]\n",
            "[0.005384653170496564] [tensor(260.)] [2]\n",
            "[0.005137102473835534] [tensor(261.)] [2]\n",
            "[0.00524551281904473] [tensor(261.)] [3]\n",
            "[3.2322870744941435e-05] [tensor(262.)] [0]\n",
            "[0.00027350078782842775] [tensor(239.)] [4]\n",
            "[0.028554699094406805] [tensor(262.)] [2]\n",
            "[0.03178829055610127] [tensor(262.)] [3]\n",
            "[0.010082606576255268] [tensor(263.)] [1]\n",
            "[0.0156848466536556] [tensor(239.)] [3]\n",
            "[1.3043457096961504e-06] [tensor(263.)] [3]\n",
            "[1.4283307462187538e-06] [tensor(263.)] [2]\n",
            "[0.02425086739302522] [tensor(244.)] [2]\n",
            "[0.02452616071358543] [tensor(244.)] [2]\n",
            "[0.0014675561103358167] [tensor(255.)] [0]\n",
            "[0.0015283591526701573] [tensor(255.)] [0]\n",
            "[0.00418560779814614] [tensor(266.)] [0]\n",
            "[0.0019882722783389163] [tensor(266.)] [1]\n",
            "[0.021603237733883694] [tensor(265.)] [0]\n",
            "[0.0059726591097879365] [tensor(266.)] [2]\n",
            "[0.001725026468509503] [tensor(255.)] [3]\n",
            "[0.00015674220604534382] [tensor(267.)] [1]\n",
            "[0.002486441557072665] [tensor(267.)] [3]\n",
            "[0.0009564237910766361] [tensor(267.)] [0]\n",
            "[0.000218531574121252] [tensor(268.)] [0]\n",
            "[0.00015118683380413098] [tensor(268.)] [1]\n",
            "[0.007734823786692845] [tensor(246.)] [6]\n",
            "[0.010201407029774543] [tensor(268.)] [2]\n",
            "[0.014528574325200414] [tensor(269.)] [0]\n",
            "[0.004698831226337354] [tensor(269.)] [1]\n",
            "[0.02704204619120299] [tensor(269.)] [2]\n",
            "[0.05453353634908293] [tensor(269.)] [3]\n",
            "[0.0014778916368607736] [tensor(248.)] [3]\n",
            "[0.0016787562564168441] [tensor(284.)] [0]\n",
            "[0.004084701911515935] [tensor(270.)] [3]\n",
            "[0.0003363636050995734] [tensor(270.)] [2]\n",
            "[0.0005576768191478227] [tensor(271.)] [0]\n",
            "[0.0016591110168762972] [tensor(271.)] [1]\n",
            "[0.0148162951686341] [tensor(271.)] [3]\n",
            "[0.013189925881149657] [tensor(271.)] [2]\n",
            "[0.002275539523367221] [tensor(272.)] [0]\n",
            "[0.013203513402082388] [tensor(274.)] [1]\n",
            "[0.024560642234937098] [tensor(272.)] [3]\n",
            "[0.014042651653478616] [tensor(283.)] [0]\n",
            "[0.0028058732147305653] [tensor(273.)] [0]\n",
            "[0.00854652790914426] [tensor(273.)] [3]\n",
            "[0.007904276758208127] [tensor(253.)] [2]\n",
            "[0.03154646619474578] [tensor(246.)] [6]\n",
            "[0.0012281277943976849] [tensor(274.)] [0]\n",
            "[0.006933223481624485] [tensor(274.)] [1]\n",
            "[0.0014592156830402151] [tensor(274.)] [2]\n",
            "[0.00037269941428454915] [tensor(275.)] [0]\n",
            "[0.0014699034805035387] [tensor(275.)] [1]\n",
            "[0.012100573829374763] [tensor(260.)] [2]\n",
            "[0.02731119262559928] [tensor(237.)] [2]\n",
            "[0.005452172228289151] [tensor(276.)] [0]\n",
            "[0.043989729312403636] [tensor(249.)] [0]\n",
            "[0.00046419148435123444] [tensor(276.)] [2]\n",
            "[0.013259734587946935] [tensor(256.)] [2]\n",
            "[0.13532084319500537] [tensor(229.)] [3]\n",
            "[0.009345761887489179] [tensor(235.)] [0]\n",
            "[0.0003432232963376719] [tensor(277.)] [2]\n",
            "[0.1369079551510219] [tensor(277.)] [3]\n",
            "[0.0032797609914542313] [tensor(278.)] [0]\n",
            "[0.0024769199863229584] [tensor(278.)] [3]\n",
            "[0.0032797609914542313] [tensor(278.)] [0]\n",
            "[0.005180183824518538] [tensor(278.)] [1]\n",
            "[0.00250920916114243] [tensor(273.)] [1]\n",
            "[0.0020744317567067405] [tensor(273.)] [1]\n",
            "[0.011110720644636331] [tensor(233.)] [0]\n",
            "[0.11155221245366234] [tensor(279.)] [3]\n",
            "[0.035091306048841] [tensor(273.)] [3]\n",
            "[0.007756076005470923] [tensor(233.)] [1]\n",
            "[0.0047427187009108415] [tensor(280.)] [0]\n",
            "[0.0014434171804821039] [tensor(280.)] [1]\n",
            "[0.0009647614683270102] [tensor(280.)] [3]\n",
            "[0.0057585495577853595] [tensor(280.)] [2]\n",
            "[0.025896407015944835] [tensor(279.)] [2]\n",
            "[0.0013845028727222676] [tensor(248.)] [0]\n",
            "[0.00043917406898507153] [tensor(281.)] [2]\n",
            "[0.0009564686224345786] [tensor(248.)] [1]\n",
            "[0.0001512751312440383] [tensor(282.)] [0]\n",
            "[1.4398871653821706e-06] [tensor(282.)] [2]\n",
            "[1.5418225919058044e-06] [tensor(282.)] [1]\n",
            "[3.116563765822715e-05] [tensor(283.)] [0]\n",
            "[0.016313037396509137] [tensor(258.)] [2]\n",
            "[0.006767242323926473] [tensor(283.)] [1]\n",
            "[0.008234460866209013] [tensor(272.)] [2]\n",
            "[0.0009081745737448025] [tensor(284.)] [0]\n",
            "[0.001844359306964735] [tensor(284.)] [1]\n",
            "[0.008740468147625488] [tensor(245.)] [0]\n",
            "[0.0650634900132542] [tensor(284.)] [4]\n",
            "[0.04344349118574685] [tensor(284.)] [2]\n",
            "% 70.16129032258064 de las imagenes fueron clasificadas correctamente.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKvbggd1htPG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a31865fb-e5f9-4c92-b3dd-eaf719a7cd3a"
      },
      "source": [
        "test_dataset.class_to_idx"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AlCapo': 0,\n",
              " 'Alibaba': 1,\n",
              " 'Americancop': 2,\n",
              " 'Aquaman': 3,\n",
              " 'Ariana': 4,\n",
              " 'Artist': 5,\n",
              " 'Astronaut': 6,\n",
              " 'Avatara': 7,\n",
              " 'Aztec': 8,\n",
              " 'BabyBoyKeychain': 9,\n",
              " 'Bali': 10,\n",
              " 'Balifemale': 11,\n",
              " 'BalletDancer': 12,\n",
              " 'Balthazar': 13,\n",
              " 'Basketball': 14,\n",
              " 'Bat': 15,\n",
              " 'Batmangreyholdy': 16,\n",
              " 'BavarianMan': 17,\n",
              " 'BavarianWoman': 18,\n",
              " 'Bicycles': 19,\n",
              " 'BigBen': 20,\n",
              " 'Black': 21,\n",
              " 'BlackSheep': 22,\n",
              " 'BlackStar': 23,\n",
              " 'Blacksheepmini': 24,\n",
              " 'Blue': 25,\n",
              " 'BlueSuede': 26,\n",
              " 'Bluemini': 27,\n",
              " 'BohemianQuacksody': 28,\n",
              " 'Bombshell': 29,\n",
              " 'Borntosun': 30,\n",
              " 'Bowling': 31,\n",
              " 'Boxer': 32,\n",
              " 'Brit': 33,\n",
              " 'Cactus': 34,\n",
              " 'Caesar': 35,\n",
              " 'Cannabis': 36,\n",
              " 'CaptainQuack': 37,\n",
              " 'Carnivalman': 38,\n",
              " 'Carnivalwoman': 39,\n",
              " 'Chef': 40,\n",
              " 'Chewquacker': 41,\n",
              " 'Chicken': 42,\n",
              " 'ChimneySweep': 43,\n",
              " 'Christmasjumper': 44,\n",
              " 'Cleaningfairy': 45,\n",
              " 'Clouds': 46,\n",
              " 'Cop': 47,\n",
              " 'Crocodile': 48,\n",
              " 'Cyber': 49,\n",
              " 'Cybersoldier': 50,\n",
              " 'Dali': 51,\n",
              " 'Dark': 52,\n",
              " 'DarkDuckWoman': 53,\n",
              " 'Delftblue': 54,\n",
              " 'Diamont': 55,\n",
              " 'Dino': 56,\n",
              " 'Diva': 57,\n",
              " 'DoctorSmartstein': 58,\n",
              " 'Dragon': 59,\n",
              " 'Driver': 60,\n",
              " 'Driverwoman': 61,\n",
              " 'DuckFadar': 62,\n",
              " 'DuckYou': 63,\n",
              " 'Ducktrix': 64,\n",
              " 'Easteregg': 65,\n",
              " 'Eastfrisian': 66,\n",
              " 'Elephant': 67,\n",
              " 'Engineer': 68,\n",
              " 'Eskimowithbaby': 69,\n",
              " 'Fadar': 70,\n",
              " 'Fairy': 71,\n",
              " 'FairyPrincess': 72,\n",
              " 'Fairyholdy': 73,\n",
              " 'Farmer': 74,\n",
              " 'FarmerWoman': 75,\n",
              " 'Fashion': 76,\n",
              " 'Firemanblack': 77,\n",
              " 'Fitness': 78,\n",
              " 'Fitnessgirl': 79,\n",
              " 'Flamingo': 80,\n",
              " 'FloatingStones': 81,\n",
              " 'FootballPlayer': 82,\n",
              " 'Frankenstein': 83,\n",
              " 'Frankensteinwoman': 84,\n",
              " 'Freedomkeychain': 85,\n",
              " 'Freud': 86,\n",
              " 'GOT': 87,\n",
              " 'GermanMaleKeychain': 88,\n",
              " 'Getwell': 89,\n",
              " 'Getwellmood': 90,\n",
              " 'Gingerbread': 91,\n",
              " 'Godfeather': 92,\n",
              " 'Goodluck': 93,\n",
              " 'Green': 94,\n",
              " 'GreetingSign': 95,\n",
              " 'GrimReaper': 96,\n",
              " 'GuardianAngel': 97,\n",
              " 'GuardianAngelWhite': 98,\n",
              " 'Harryponder': 99,\n",
              " 'Heart': 100,\n",
              " 'HeavyMetal': 101,\n",
              " 'Hedgehog': 102,\n",
              " 'Hippie': 103,\n",
              " 'HippieWoman': 104,\n",
              " 'Hipster': 105,\n",
              " 'HipsterWoman': 106,\n",
              " 'Holdypinkcrown': 107,\n",
              " 'HolidayMan': 108,\n",
              " 'Holidaywoman': 109,\n",
              " 'Holland': 110,\n",
              " 'Hunter': 111,\n",
              " 'Icehockey': 112,\n",
              " 'Incredible': 113,\n",
              " 'Japanese': 114,\n",
              " 'Josef': 115,\n",
              " 'Kangaroo': 116,\n",
              " 'KisstheDemon': 117,\n",
              " 'Knight': 118,\n",
              " 'KungFu': 119,\n",
              " 'Lama': 120,\n",
              " 'Lawyer': 121,\n",
              " 'Lighthouse': 122,\n",
              " 'Lingerie': 123,\n",
              " 'Loveyou': 124,\n",
              " 'Loveyoumood': 125,\n",
              " 'LukePondwalker': 126,\n",
              " 'LuxuryPirate': 127,\n",
              " 'LuxuryRainbow': 128,\n",
              " 'M': 129,\n",
              " 'Maria': 130,\n",
              " 'Materialbird': 131,\n",
              " 'Mini80scube': 132,\n",
              " 'MiniSpace': 133,\n",
              " 'Miniahoy': 134,\n",
              " 'Minidonut': 135,\n",
              " 'Minihemp': 136,\n",
              " 'Minileopard': 137,\n",
              " 'Minilovelove': 138,\n",
              " 'Minipopheart': 139,\n",
              " 'Minipunkrocker': 140,\n",
              " 'Missyou': 141,\n",
              " 'Mom': 142,\n",
              " 'MonaLisa': 143,\n",
              " 'Monkey': 144,\n",
              " 'Moodmissyou': 145,\n",
              " 'Nerd': 146,\n",
              " 'Ninja': 147,\n",
              " 'Nordman': 148,\n",
              " 'Nurse': 149,\n",
              " 'Nutcracker': 150,\n",
              " 'OnePond': 151,\n",
              " 'OwlBrown': 152,\n",
              " 'Paparazzi': 153,\n",
              " 'Paramedic': 154,\n",
              " 'Peacock': 155,\n",
              " 'Photographer': 156,\n",
              " 'Picquacko': 157,\n",
              " 'Pig': 158,\n",
              " 'Pigeon': 159,\n",
              " 'Piku': 160,\n",
              " 'Pilot': 161,\n",
              " 'PilotRing': 162,\n",
              " 'PinkUnicornKeychain': 163,\n",
              " 'Pinkmini': 164,\n",
              " 'Pinkunicornmini': 165,\n",
              " 'Pinkwhitehearts': 166,\n",
              " 'Pinky': 167,\n",
              " 'Piratered': 168,\n",
              " 'PoliceWoman': 169,\n",
              " 'Pondtrooper': 170,\n",
              " 'Pool': 171,\n",
              " 'PopIcon': 172,\n",
              " 'PositivePoem': 173,\n",
              " 'Princess': 174,\n",
              " 'PrincessLayer': 175,\n",
              " 'Purplewaves': 176,\n",
              " 'QuackodileRock': 177,\n",
              " 'Queen': 178,\n",
              " 'Rasta': 179,\n",
              " 'Red': 180,\n",
              " 'RedStar': 181,\n",
              " 'Redwhitehearts': 182,\n",
              " 'Robot': 183,\n",
              " 'Roman': 184,\n",
              " 'Row': 185,\n",
              " 'RoyalGuard': 186,\n",
              " 'SM': 187,\n",
              " 'SargentPeepersLonelyHotTubBand': 188,\n",
              " 'SchoolBoy': 189,\n",
              " 'SchoolGirl': 190,\n",
              " 'Scotsman': 191,\n",
              " 'ScottishPiper': 192,\n",
              " 'Shepherd': 193,\n",
              " 'Sherlock': 194,\n",
              " 'Skater': 195,\n",
              " 'Sleepy': 196,\n",
              " 'Snail': 197,\n",
              " 'Snake': 198,\n",
              " 'Soccerred': 199,\n",
              " 'Socceryellow': 200,\n",
              " 'Soldier': 201,\n",
              " 'Sparta': 202,\n",
              " 'StarPopper': 203,\n",
              " 'Submarine': 204,\n",
              " 'Sunny': 205,\n",
              " 'Superhero': 206,\n",
              " 'SurferBoy': 207,\n",
              " 'SurferGirl': 208,\n",
              " 'Surgeon': 209,\n",
              " 'Swimmer': 210,\n",
              " 'Swiss': 211,\n",
              " 'Tennis': 212,\n",
              " 'TennisMan': 213,\n",
              " 'Thankyou': 214,\n",
              " 'Thief': 215,\n",
              " 'Thor': 216,\n",
              " 'TourdeDuck': 217,\n",
              " 'Tourist': 218,\n",
              " 'Travel': 219,\n",
              " 'Trooper': 220,\n",
              " 'Trump': 221,\n",
              " 'Tulips': 222,\n",
              " 'Tullip': 223,\n",
              " 'Turtle': 224,\n",
              " 'UnicornLight': 225,\n",
              " 'Unicornwhite': 226,\n",
              " 'Unicornwhiteholdy': 227,\n",
              " 'Unicornwhithholdy': 228,\n",
              " 'VikingWoman': 229,\n",
              " 'Vincent': 230,\n",
              " 'Warden': 231,\n",
              " 'White': 232,\n",
              " 'WhiteUnicornKeychain': 233,\n",
              " 'Whiteredhearts': 234,\n",
              " 'Whitesheepmini': 235,\n",
              " 'Whiteunicornmini': 236,\n",
              " 'Whooping': 237,\n",
              " 'Wildtiger': 238,\n",
              " 'Woody': 239,\n",
              " 'Yellowmini': 240,\n",
              " 'Yoga': 241,\n",
              " 'Zig': 242,\n",
              " 'ZiggyStarduck': 243,\n",
              " 'Zodiac': 244,\n",
              " 'amore': 245,\n",
              " 'biker': 246,\n",
              " 'buddha': 247,\n",
              " 'businessman': 248,\n",
              " 'businesswoman': 249,\n",
              " 'chief': 250,\n",
              " 'coffee': 251,\n",
              " 'cowboy': 252,\n",
              " 'easterbunny': 253,\n",
              " 'easterchocolate': 254,\n",
              " 'euro': 255,\n",
              " 'frenchman': 256,\n",
              " 'gamerboy': 257,\n",
              " 'gamergirl': 258,\n",
              " 'hairdresser': 259,\n",
              " 'indianman': 260,\n",
              " 'indianwoman': 261,\n",
              " 'influencer': 262,\n",
              " 'kisses': 263,\n",
              " 'leopard': 264,\n",
              " 'lovelove': 265,\n",
              " 'mermaid': 266,\n",
              " 'moonandstars': 267,\n",
              " 'nun': 268,\n",
              " 'paint': 269,\n",
              " 'painter': 270,\n",
              " 'panda': 271,\n",
              " 'pirateparrot': 272,\n",
              " 'punkiwoman': 273,\n",
              " 'rabbi': 274,\n",
              " 'royalqueen': 275,\n",
              " 'runner': 276,\n",
              " 'sauna': 277,\n",
              " 'shopping': 278,\n",
              " 'sunday': 279,\n",
              " 'theflame': 280,\n",
              " 'unclesam': 281,\n",
              " 'unicorn': 282,\n",
              " 'viking': 283,\n",
              " 'volleyball': 284}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    }
  ]
}
