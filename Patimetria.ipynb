{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Patimetria2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOZfsm7C7WWO0hp5TlF5vF5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mar3334/Patimetria/blob/main/Patimetria.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IsugSfCY_zE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90cb4297-50a5-4cf1-9493-2b2946c084bc"
      },
      "source": [
        "from google.colab import drive  # Se importa el drive donde estan todos los .py y las imagenes utilizadas, esta celda debe ser modificada en caso de que se quiera probar el codigo en otro equipo.\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xh-5LoycHuly",
        "outputId": "655cc7fb-acb1-482d-a76d-22e774a392f7"
      },
      "source": [
        "!pip install torch==1.4.0 torchvision==0.5.0 # Se instala la version de torch y torchvision necesaria para poder usar el codigo."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4MB 20kB/s \n",
            "\u001b[?25hCollecting torchvision==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/90/6141bf41f5655c78e24f40f710fdd4f8a8aff6c8b7c6f0328240f649bdbe/torchvision-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 30.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.19.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "  Found existing installation: torchvision 0.8.1+cu101\n",
            "    Uninstalling torchvision-0.8.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.8.1+cu101\n",
            "Successfully installed torch-1.4.0 torchvision-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eppi8CjtPagb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93d0d92a-02cd-4677-c1ef-8fea07eecea3"
      },
      "source": [
        "!cp -rf /content/drive/MyDrive/siamese-triplet /content/drive/MyDrive/siamese-triplet # Se copia en el drive cualquier cambio que se realize a los .py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot copy a directory, '/content/drive/MyDrive/siamese-triplet', into itself, '/content/drive/MyDrive/siamese-triplet/siamese-triplet'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB-oh40GYmf8"
      },
      "source": [
        "# Se importar todos los modulos y funciones necesarios\r\n",
        "import numpy as np\r\n",
        "import matplotlib\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import torch\r\n",
        "from torch.optim import lr_scheduler\r\n",
        "import torch.optim as optim\r\n",
        "from torch.autograd import Variable\r\n",
        "from torchvision import models, transforms\r\n",
        "from PIL import Image\r\n",
        "import sys\r\n",
        "sys.path.append('/content/drive/MyDrive/siamese-triplet')\r\n",
        "\r\n",
        "#La siguiente importacion es de un codigo diseñado para el proyecto patimetria:\r\n",
        "from duckies_dataset import DuckieDataset, Rescale\r\n",
        "#Los siguientes modulos son versiones modificadas de .py de terceros adapatados para utilizar en el proyecto patimetria.\r\n",
        "# Los modulos originales se encuentran en el siguiente git: https://github.com/adambielski/siamese-triplet\r\n",
        "from networks import VGGEmbeddingNet, EmbeddingNet, TripletNet\r\n",
        "from trainer import fit, train_epoch, test_epoch\r\n",
        "from datasets import TripletMNIST\r\n",
        "from losses import TripletLoss"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-clKeEwY1Ot"
      },
      "source": [
        "# Se cargan 2 modelos a utilizar.\r\n",
        "vgg_model = VGGEmbeddingNet()\r\n",
        "emb_net = EmbeddingNet()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLOX2DaaY-_Z"
      },
      "source": [
        "# Se define una transformacion que convierte las imagenes a tensores de tamaño [224, 224]\r\n",
        "trans = transforms.Compose([Rescale(224),\r\n",
        "                            transforms.ToTensor()])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld4nhSBNZmy8"
      },
      "source": [
        "# Se definen los datasets de entrenamiento y de testeo.\r\n",
        "train_dataset = DuckieDataset(\"/content/drive/MyDrive/train\", transform= trans)\r\n",
        "test_dataset = DuckieDataset(\"/content/drive/MyDrive/train\", train=False, transform= trans)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn2gkk-saRZq",
        "outputId": "72cf7301-4e28-4281-b5ce-6acb9f792a3a"
      },
      "source": [
        "cuda = torch.cuda.is_available()\r\n",
        "%matplotlib inline\r\n",
        "# Set up data loaders\r\n",
        "\r\n",
        "triplet_train_dataset = TripletMNIST(train_dataset) # Returns triplets of images\r\n",
        "triplet_test_dataset = TripletMNIST(test_dataset)\r\n",
        "batch_size = 32\r\n",
        "kwargs = {'num_workers': 8, 'pin_memory': True} if cuda else {}\r\n",
        "triplet_train_loader = torch.utils.data.DataLoader(triplet_train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\r\n",
        "triplet_test_loader = torch.utils.data.DataLoader(triplet_test_dataset, batch_size=batch_size, shuffle=False, **kwargs)\r\n",
        "\r\n",
        "# Set up the network and training parameters\r\n",
        "\r\n",
        "margin = 1.\r\n",
        "embedding_net = EmbeddingNet()\r\n",
        "model = TripletNet(vgg_model)\r\n",
        "if cuda:\r\n",
        "    model.cuda()\r\n",
        "loss_fn = TripletLoss(margin)\r\n",
        "lr = 1e-3\r\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\r\n",
        "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\r\n",
        "n_epochs = 15\r\n",
        "log_interval = 500"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk7ukB4ga3RO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dfbca91-dd11-443d-878f-393420302675"
      },
      "source": [
        "fit(triplet_train_loader, triplet_test_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval) #Se empieza a entrenar la red."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: [0/1080 (0%)]\tLoss: 0.761868\n",
            "Epoch: 1/15. Train set: Average loss: 0.8691\n",
            "Epoch: 1/15. Validation set: Average loss: 0.8531\n",
            "Train: [0/1080 (0%)]\tLoss: 0.924274\n",
            "Epoch: 2/15. Train set: Average loss: 0.6689\n",
            "Epoch: 2/15. Validation set: Average loss: 0.5564\n",
            "Train: [0/1080 (0%)]\tLoss: 0.482481\n",
            "Epoch: 3/15. Train set: Average loss: 0.4066\n",
            "Epoch: 3/15. Validation set: Average loss: 0.4278\n",
            "Train: [0/1080 (0%)]\tLoss: 0.483906\n",
            "Epoch: 4/15. Train set: Average loss: 0.4737\n",
            "Epoch: 4/15. Validation set: Average loss: 0.4617\n",
            "Train: [0/1080 (0%)]\tLoss: 0.595181\n",
            "Epoch: 5/15. Train set: Average loss: 0.4370\n",
            "Epoch: 5/15. Validation set: Average loss: 0.3967\n",
            "Train: [0/1080 (0%)]\tLoss: 0.453443\n",
            "Epoch: 6/15. Train set: Average loss: 0.4158\n",
            "Epoch: 6/15. Validation set: Average loss: 0.3829\n",
            "Train: [0/1080 (0%)]\tLoss: 0.466128\n",
            "Epoch: 7/15. Train set: Average loss: 0.3535\n",
            "Epoch: 7/15. Validation set: Average loss: 0.4570\n",
            "Train: [0/1080 (0%)]\tLoss: 0.536488\n",
            "Epoch: 8/15. Train set: Average loss: 0.3336\n",
            "Epoch: 8/15. Validation set: Average loss: 0.4238\n",
            "Train: [0/1080 (0%)]\tLoss: 0.440386\n",
            "Epoch: 9/15. Train set: Average loss: 0.3305\n",
            "Epoch: 9/15. Validation set: Average loss: 0.4152\n",
            "Train: [0/1080 (0%)]\tLoss: 0.267955\n",
            "Epoch: 10/15. Train set: Average loss: 0.3296\n",
            "Epoch: 10/15. Validation set: Average loss: 0.4024\n",
            "Train: [0/1080 (0%)]\tLoss: 0.334400\n",
            "Epoch: 11/15. Train set: Average loss: 0.3213\n",
            "Epoch: 11/15. Validation set: Average loss: 0.4145\n",
            "Train: [0/1080 (0%)]\tLoss: 0.272328\n",
            "Epoch: 12/15. Train set: Average loss: 0.3202\n",
            "Epoch: 12/15. Validation set: Average loss: 0.4222\n",
            "Train: [0/1080 (0%)]\tLoss: 0.374766\n",
            "Epoch: 13/15. Train set: Average loss: 0.3101\n",
            "Epoch: 13/15. Validation set: Average loss: 0.4095\n",
            "Train: [0/1080 (0%)]\tLoss: 0.297601\n",
            "Epoch: 14/15. Train set: Average loss: 0.2935\n",
            "Epoch: 14/15. Validation set: Average loss: 0.3887\n",
            "Train: [0/1080 (0%)]\tLoss: 0.340950\n",
            "Epoch: 15/15. Train set: Average loss: 0.2903\n",
            "Epoch: 15/15. Validation set: Average loss: 0.3847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OF26aefvTNlk"
      },
      "source": [
        "# Define functions to extract embeddings using diferent datasets\r\n",
        "def extract_embeddings(dataset, model, dims = 1024, opt = None):\r\n",
        "    with torch.no_grad():\r\n",
        "        model.eval()\r\n",
        "        embeddings = np.zeros((len(dataset), dims))\r\n",
        "        labels = list()\r\n",
        "        for k, it_ in enumerate(dataset):\r\n",
        "            images = it_[0].unsqueeze_(0)\r\n",
        "            images = images.cuda()\r\n",
        "            target = it_[1]\r\n",
        "            if opt is None:\r\n",
        "                aux = model.get_embedding(images).data.cpu().numpy()\r\n",
        "            else:\r\n",
        "                aux = model.get_embedding(images, opt).data.cpu().numpy()\r\n",
        "            embeddings[k] = aux.reshape(1, dims)\r\n",
        "            labels.append(target)\r\n",
        "    return embeddings, labels\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGORG9c1Twos"
      },
      "source": [
        "embeddings, labels = extract_embeddings(train_dataset, vgg_model, dims = 512)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUfuE4B2pnlI"
      },
      "source": [
        "# n_closest_images: (str), (int) ---> list\r\n",
        "# Funcion que recibe la ruta de una imagen y de manera opcional un numero entero\"n\" (por defecto 5), que escribe 3 listas y entrega 1:\r\n",
        "# Near_list: lista que contiene las n distancias mas cortas con respecto a la imagen entregada\r\n",
        "# List_labels: lista que contiene las etiquetas correspondientes a las \"n\" imagenes con distancias mas cortas. Esta lista es entregada por la funcion.\r\n",
        "# Label_ubication_list: lista que entrega la posicion de las \"n\" imagenes mas cercanas con respecto a su etiqueta.\r\n",
        "\r\n",
        "def n_closest_images(image, n=5):\r\n",
        "  img = Image.open(image).convert('RGB')\r\n",
        "  img = trans(img)\r\n",
        "  emb_img = vgg_model(img.unsqueeze(0).cuda())\r\n",
        "  embedding_img = emb_img.data.cpu().numpy()\r\n",
        "  list_dist, list_labels, neat_list, label_ubication_list = [], [], [], []\r\n",
        "  for i in range(embeddings.shape[0]):\r\n",
        "    emb2 = embeddings[i,:]\r\n",
        "    dist = np.sum((emb2 - embedding_img)**2)\r\n",
        "    list_dist.append(dist)\r\n",
        "  neat_list[:] = list_dist\r\n",
        "  neat_list.sort()\r\n",
        "  for i in range(n):\r\n",
        "    position = list_dist.index(neat_list[i])\r\n",
        "    label_ubication = position - labels.index(labels[position])\r\n",
        "    label_ubication_list.append(label_ubication)\r\n",
        "    list_labels.append(labels[position])\r\n",
        "  print (neat_list[:n], list_labels, label_ubication_list)\r\n",
        "  return list_labels"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYZvv4tkMwgC",
        "outputId": "27f14272-18e6-4c77-a466-f44aec737828"
      },
      "source": [
        "n_closest_images(\"/content/drive/MyDrive/Patos/Mafia.png\")[0]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.016945727663533878, 0.01743076364299392, 0.019738291940745816, 0.02498025946671655, 0.029736553005138697] [tensor(153.), tensor(153.), tensor(64.), tensor(22.), tensor(22.)] [3, 0, 6, 2, 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(153.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLrMbPxjb5fr"
      },
      "source": [
        "# closest_image_after_rotation: (str) ---> list\r\n",
        "# Funcion que recibe la ruta de una imagen, escribe 3 numeros y entrega 1:\r\n",
        "# neat_list[:1]: Corresponde a la distancia mas corta entre la imagen entregada y una del dataset\r\n",
        "# list_labels: Corresponde a la lista con las etiquetas de las imagenes del dataset, ordenadas desde las imagenes mas cercanas hasta las mas alejadas con respecto a la imagen entregada.\r\n",
        "# esta lista es entregada por la funcion.\r\n",
        "# Label_ubication_list: lista que entrega la posicion de las imagenes con respecto a su etiqueta. (Nota: si en la etiqueta tiene \"n\" imagenes, 0 representa la primera imagen y\r\n",
        "# \"k\" representa la \"k+1\"-esima imagen)\"\r\n",
        "def closest_image_after_rotation(image):\r\n",
        "  img = Image.open(image).convert('RGB')\r\n",
        "  flip = transforms.RandomHorizontalFlip(p=1)\r\n",
        "  img = flip(img)\r\n",
        "  img = trans(img)\r\n",
        "  emb_img = vgg_model(img.unsqueeze(0).cuda())\r\n",
        "  embedding_img = emb_img.data.cpu().numpy()\r\n",
        "  list_dist, list_labels, neat_list, label_ubication_list = [], [], [], []\r\n",
        "  for i in range(embeddings.shape[0]):\r\n",
        "    emb2 = embeddings[i,:]\r\n",
        "    dist = np.sum((emb2 - embedding_img)**2)\r\n",
        "    list_dist.append(dist)\r\n",
        "  neat_list[:] = list_dist\r\n",
        "  neat_list.sort()\r\n",
        "  for i in range(1):\r\n",
        "    position = list_dist.index(neat_list[i])\r\n",
        "    label_ubication = position - labels.index(labels[position])\r\n",
        "    label_ubication_list.append(label_ubication)\r\n",
        "    list_labels.append(labels[position])\r\n",
        "  return list_labels"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ2vTN9wLlwv"
      },
      "source": [
        "# percentage_check (dataset) ---> ()\r\n",
        "# Funcion que recibe un dataset y rota las imagenes del mismo para luego pasarlas por la red y verificar cuantas imagenes son clasificadas correctamente en su etiqueta.\r\n",
        "# El resultado es escrito como un porcentaje\r\n",
        "def percentage_check(dataset):\r\n",
        "  Right = 0\r\n",
        "  for i in range(len(dataset.data)):\r\n",
        "    img = dataset.data[i]\r\n",
        "    label= closest_image_after_rotation(img)\r\n",
        "    if label[0] == dataset.targets[i]:\r\n",
        "      Right += 1 \r\n",
        "  Total = len(dataset.targets)\r\n",
        "  Percentage = 100.0*Right/Total\r\n",
        "  print (\"% \" + str(Percentage) +\" de las imagenes fueron clasificadas correctamente.\")\r\n",
        "\r\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtNi2lfKRodR",
        "outputId": "68298563-fb0c-4b8b-8f14-c4b4d2d7207b"
      },
      "source": [
        "percentage_check(test_dataset)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% 88.30645161290323 de las imagenes fueron clasificadas correctamente.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKvbggd1htPG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc914f07-e166-45c6-ba3b-cb4173b972ab"
      },
      "source": [
        "test_dataset.class_to_idx"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AlCapo': 0,\n",
              " 'Alibaba': 1,\n",
              " 'Americancop': 2,\n",
              " 'Aquaman': 3,\n",
              " 'Ariana': 4,\n",
              " 'Artist': 5,\n",
              " 'Astronaut': 6,\n",
              " 'Avatara': 7,\n",
              " 'Aztec': 8,\n",
              " 'BabyBoyKeychain': 9,\n",
              " 'Bali': 10,\n",
              " 'Balifemale': 11,\n",
              " 'BalletDancer': 12,\n",
              " 'Balthazar': 13,\n",
              " 'Basketball': 14,\n",
              " 'Bat': 15,\n",
              " 'Batmangreyholdy': 16,\n",
              " 'BavarianMan': 17,\n",
              " 'BavarianWoman': 18,\n",
              " 'Bicycles': 19,\n",
              " 'BigBen': 20,\n",
              " 'Black': 21,\n",
              " 'BlackSheep': 22,\n",
              " 'BlackStar': 23,\n",
              " 'Blacksheepmini': 24,\n",
              " 'Blue': 25,\n",
              " 'BlueSuede': 26,\n",
              " 'Bluemini': 27,\n",
              " 'BohemianQuacksody': 28,\n",
              " 'Bombshell': 29,\n",
              " 'Borntosun': 30,\n",
              " 'Bowling': 31,\n",
              " 'Boxer': 32,\n",
              " 'Brit': 33,\n",
              " 'Cactus': 34,\n",
              " 'Caesar': 35,\n",
              " 'Cannabis': 36,\n",
              " 'CaptainQuack': 37,\n",
              " 'Carnivalman': 38,\n",
              " 'Carnivalwoman': 39,\n",
              " 'Chef': 40,\n",
              " 'Chewquacker': 41,\n",
              " 'Chicken': 42,\n",
              " 'ChimneySweep': 43,\n",
              " 'Christmasjumper': 44,\n",
              " 'Cleaningfairy': 45,\n",
              " 'Clouds': 46,\n",
              " 'Cop': 47,\n",
              " 'Crocodile': 48,\n",
              " 'Cyber': 49,\n",
              " 'Cybersoldier': 50,\n",
              " 'Dali': 51,\n",
              " 'Dark': 52,\n",
              " 'DarkDuckWoman': 53,\n",
              " 'Delftblue': 54,\n",
              " 'Diamont': 55,\n",
              " 'Dino': 56,\n",
              " 'Diva': 57,\n",
              " 'DoctorSmartstein': 58,\n",
              " 'Dragon': 59,\n",
              " 'Driver': 60,\n",
              " 'Driverwoman': 61,\n",
              " 'DuckFadar': 62,\n",
              " 'DuckYou': 63,\n",
              " 'Ducktrix': 64,\n",
              " 'Easteregg': 65,\n",
              " 'Eastfrisian': 66,\n",
              " 'Elephant': 67,\n",
              " 'Engineer': 68,\n",
              " 'Eskimowithbaby': 69,\n",
              " 'Fadar': 70,\n",
              " 'Fairy': 71,\n",
              " 'FairyPrincess': 72,\n",
              " 'Fairyholdy': 73,\n",
              " 'Farmer': 74,\n",
              " 'FarmerWoman': 75,\n",
              " 'Fashion': 76,\n",
              " 'Firemanblack': 77,\n",
              " 'Fitness': 78,\n",
              " 'Fitnessgirl': 79,\n",
              " 'Flamingo': 80,\n",
              " 'FloatingStones': 81,\n",
              " 'FootballPlayer': 82,\n",
              " 'Frankenstein': 83,\n",
              " 'Frankensteinwoman': 84,\n",
              " 'Freedomkeychain': 85,\n",
              " 'Freud': 86,\n",
              " 'GOT': 87,\n",
              " 'GermanMaleKeychain': 88,\n",
              " 'Getwell': 89,\n",
              " 'Getwellmood': 90,\n",
              " 'Gingerbread': 91,\n",
              " 'Godfeather': 92,\n",
              " 'Goodluck': 93,\n",
              " 'Green': 94,\n",
              " 'GreetingSign': 95,\n",
              " 'GrimReaper': 96,\n",
              " 'GuardianAngel': 97,\n",
              " 'GuardianAngelWhite': 98,\n",
              " 'Harryponder': 99,\n",
              " 'Heart': 100,\n",
              " 'HeavyMetal': 101,\n",
              " 'Hedgehog': 102,\n",
              " 'Hippie': 103,\n",
              " 'HippieWoman': 104,\n",
              " 'Hipster': 105,\n",
              " 'HipsterWoman': 106,\n",
              " 'Holdypinkcrown': 107,\n",
              " 'HolidayMan': 108,\n",
              " 'Holidaywoman': 109,\n",
              " 'Holland': 110,\n",
              " 'Hunter': 111,\n",
              " 'Icehockey': 112,\n",
              " 'Incredible': 113,\n",
              " 'Japanese': 114,\n",
              " 'Josef': 115,\n",
              " 'Kangaroo': 116,\n",
              " 'KisstheDemon': 117,\n",
              " 'Knight': 118,\n",
              " 'KungFu': 119,\n",
              " 'Lama': 120,\n",
              " 'Lawyer': 121,\n",
              " 'Lighthouse': 122,\n",
              " 'Lingerie': 123,\n",
              " 'Loveyou': 124,\n",
              " 'Loveyoumood': 125,\n",
              " 'LukePondwalker': 126,\n",
              " 'LuxuryPirate': 127,\n",
              " 'LuxuryRainbow': 128,\n",
              " 'M': 129,\n",
              " 'Maria': 130,\n",
              " 'Materialbird': 131,\n",
              " 'Mini80scube': 132,\n",
              " 'MiniSpace': 133,\n",
              " 'Miniahoy': 134,\n",
              " 'Minidonut': 135,\n",
              " 'Minihemp': 136,\n",
              " 'Minileopard': 137,\n",
              " 'Minilovelove': 138,\n",
              " 'Minipopheart': 139,\n",
              " 'Minipunkrocker': 140,\n",
              " 'Missyou': 141,\n",
              " 'Mom': 142,\n",
              " 'MonaLisa': 143,\n",
              " 'Monkey': 144,\n",
              " 'Moodmissyou': 145,\n",
              " 'Nerd': 146,\n",
              " 'Ninja': 147,\n",
              " 'Nordman': 148,\n",
              " 'Nurse': 149,\n",
              " 'Nutcracker': 150,\n",
              " 'OnePond': 151,\n",
              " 'OwlBrown': 152,\n",
              " 'Paparazzi': 153,\n",
              " 'Paramedic': 154,\n",
              " 'Peacock': 155,\n",
              " 'Photographer': 156,\n",
              " 'Picquacko': 157,\n",
              " 'Pig': 158,\n",
              " 'Pigeon': 159,\n",
              " 'Piku': 160,\n",
              " 'Pilot': 161,\n",
              " 'PilotRing': 162,\n",
              " 'PinkUnicornKeychain': 163,\n",
              " 'Pinkmini': 164,\n",
              " 'Pinkunicornmini': 165,\n",
              " 'Pinkwhitehearts': 166,\n",
              " 'Pinky': 167,\n",
              " 'Piratered': 168,\n",
              " 'PoliceWoman': 169,\n",
              " 'Pondtrooper': 170,\n",
              " 'Pool': 171,\n",
              " 'PopIcon': 172,\n",
              " 'PositivePoem': 173,\n",
              " 'Princess': 174,\n",
              " 'PrincessLayer': 175,\n",
              " 'Purplewaves': 176,\n",
              " 'QuackodileRock': 177,\n",
              " 'Queen': 178,\n",
              " 'Rasta': 179,\n",
              " 'Red': 180,\n",
              " 'RedStar': 181,\n",
              " 'Redwhitehearts': 182,\n",
              " 'Robot': 183,\n",
              " 'Roman': 184,\n",
              " 'Row': 185,\n",
              " 'RoyalGuard': 186,\n",
              " 'SM': 187,\n",
              " 'SargentPeepersLonelyHotTubBand': 188,\n",
              " 'SchoolBoy': 189,\n",
              " 'SchoolGirl': 190,\n",
              " 'Scotsman': 191,\n",
              " 'ScottishPiper': 192,\n",
              " 'Shepherd': 193,\n",
              " 'Sherlock': 194,\n",
              " 'Skater': 195,\n",
              " 'Sleepy': 196,\n",
              " 'Snail': 197,\n",
              " 'Snake': 198,\n",
              " 'Soccerred': 199,\n",
              " 'Socceryellow': 200,\n",
              " 'Soldier': 201,\n",
              " 'Sparta': 202,\n",
              " 'StarPopper': 203,\n",
              " 'Submarine': 204,\n",
              " 'Sunny': 205,\n",
              " 'Superhero': 206,\n",
              " 'SurferBoy': 207,\n",
              " 'SurferGirl': 208,\n",
              " 'Surgeon': 209,\n",
              " 'Swimmer': 210,\n",
              " 'Swiss': 211,\n",
              " 'Tennis': 212,\n",
              " 'TennisMan': 213,\n",
              " 'Thankyou': 214,\n",
              " 'Thief': 215,\n",
              " 'Thor': 216,\n",
              " 'TourdeDuck': 217,\n",
              " 'Tourist': 218,\n",
              " 'Travel': 219,\n",
              " 'Trooper': 220,\n",
              " 'Trump': 221,\n",
              " 'Tulips': 222,\n",
              " 'Tullip': 223,\n",
              " 'Turtle': 224,\n",
              " 'UnicornLight': 225,\n",
              " 'Unicornwhite': 226,\n",
              " 'Unicornwhiteholdy': 227,\n",
              " 'Unicornwhithholdy': 228,\n",
              " 'VikingWoman': 229,\n",
              " 'Vincent': 230,\n",
              " 'Warden': 231,\n",
              " 'White': 232,\n",
              " 'WhiteUnicornKeychain': 233,\n",
              " 'Whiteredhearts': 234,\n",
              " 'Whitesheepmini': 235,\n",
              " 'Whiteunicornmini': 236,\n",
              " 'Whooping': 237,\n",
              " 'Wildtiger': 238,\n",
              " 'Woody': 239,\n",
              " 'Yellowmini': 240,\n",
              " 'Yoga': 241,\n",
              " 'Zig': 242,\n",
              " 'ZiggyStarduck': 243,\n",
              " 'Zodiac': 244,\n",
              " 'amore': 245,\n",
              " 'biker': 246,\n",
              " 'buddha': 247,\n",
              " 'businessman': 248,\n",
              " 'businesswoman': 249,\n",
              " 'chief': 250,\n",
              " 'coffee': 251,\n",
              " 'cowboy': 252,\n",
              " 'easterbunny': 253,\n",
              " 'easterchocolate': 254,\n",
              " 'euro': 255,\n",
              " 'frenchman': 256,\n",
              " 'gamerboy': 257,\n",
              " 'gamergirl': 258,\n",
              " 'hairdresser': 259,\n",
              " 'indianman': 260,\n",
              " 'indianwoman': 261,\n",
              " 'influencer': 262,\n",
              " 'kisses': 263,\n",
              " 'leopard': 264,\n",
              " 'lovelove': 265,\n",
              " 'mermaid': 266,\n",
              " 'moonandstars': 267,\n",
              " 'nun': 268,\n",
              " 'paint': 269,\n",
              " 'painter': 270,\n",
              " 'panda': 271,\n",
              " 'pirateparrot': 272,\n",
              " 'punkiwoman': 273,\n",
              " 'rabbi': 274,\n",
              " 'royalqueen': 275,\n",
              " 'runner': 276,\n",
              " 'sauna': 277,\n",
              " 'shopping': 278,\n",
              " 'sunday': 279,\n",
              " 'theflame': 280,\n",
              " 'unclesam': 281,\n",
              " 'unicorn': 282,\n",
              " 'viking': 283,\n",
              " 'volleyball': 284}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    }
  ]
}