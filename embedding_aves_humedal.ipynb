{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qQYk2tOOsIU",
        "outputId": "2086507d-0df8-45d2-f1f6-99912451d923"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive  # Se importa el drive donde estan todos los .py y las imagenes utilizadas, esta celda debe ser modificada en caso de que se quiera probar el codigo en otro equipo.\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmUIqYPwPAj0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e57cd0b-979f-419b-93ff-07d67e95658f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: cd: /MyDrive/Duckietown_archivos: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "! cd /MyDrive/Duckietown_archivos && git clone https://github.com/sensxciones/Proyecto_Humedales.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GI9i9HYL5y6-",
        "outputId": "b443bd56-594e-4488-fc5f-01afe8026f66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: cd: Duckietown_archivos: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "! cd Duckietown_archivos && git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaAI2RXBPIOE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "ecb93f55-7a0d-4057-bc68-ff7e734741ae"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3a2d9a660dbc>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#La siguiente importacion es de un codigo diseñado para el proyecto patimetria:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mduckies_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDuckieDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRescale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m#Los siguientes modulos son versiones modificadas de .py de terceros adapatados para utilizar en el proyecto patimetria.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Los modulos originales se encuentran en el siguiente git: https://github.com/adambielski/siamese-triplet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'duckies_dataset'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# Se importar todos los modulos y funciones necesarios\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import sys\n",
        "sys.path.append(\"Duckietown_archivos\")\n",
        "\n",
        "#La siguiente importacion es de un codigo diseñado para el proyecto patimetria:\n",
        "from duckies_dataset import DuckieDataset, Rescale\n",
        "#Los siguientes modulos son versiones modificadas de .py de terceros adapatados para utilizar en el proyecto patimetria.\n",
        "# Los modulos originales se encuentran en el siguiente git: https://github.com/adambielski/siamese-triplet\n",
        "from networks import VGGEmbeddingNet, EmbeddingNet, TripletNet\n",
        "from trainer import fit, train_epoch, test_epoch\n",
        "from datasets import TripletMNIST\n",
        "from losses import TripletLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4SiFy4x3c7G"
      },
      "outputs": [],
      "source": [
        "vgg_model = VGGEmbeddingNet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aDLj43g4N5V"
      },
      "outputs": [],
      "source": [
        "trans = transforms.Compose([Rescale(224),\n",
        "                            transforms.ToTensor()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0IRrVnTV7_r"
      },
      "outputs": [],
      "source": [
        "referencia_dataset = DuckieDataset('/content/drive/MyDrive/ReintegrandoHumedales/inference', transform= trans)\n",
        "test_dataset = DuckieDataset('/content/drive/MyDrive/ReintegrandoHumedales/train', transform= trans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQxXVkhmsIbp"
      },
      "outputs": [],
      "source": [
        "# Cargamos el modelo\n",
        "cuda = torch.cuda.is_available()\n",
        "model = TripletNet(vgg_model)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/bird-dataset/epoch-10.pth'))\n",
        "model.eval()\n",
        "if cuda:\n",
        "    model.cuda()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SprWKfbPONx"
      },
      "outputs": [],
      "source": [
        "# Define functions to extract embeddings using diferent datasets\n",
        "def extract_embeddings(dataset, model, dims = 1024, opt = None):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        embeddings = np.zeros((len(dataset), dims))\n",
        "        labels = list()\n",
        "        for k, it_ in enumerate(dataset):\n",
        "            images = it_[0].unsqueeze_(0)\n",
        "            images = images.cuda()\n",
        "            target = it_[1]\n",
        "            if opt is None:\n",
        "                aux = model.get_embedding(images).data.cpu().numpy()\n",
        "            else:\n",
        "                aux = model.get_embedding(images, opt).data.cpu().numpy()\n",
        "            embeddings[k] = aux.reshape(1, dims)\n",
        "            labels.append(target)\n",
        "    return embeddings, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZWB1zC8Q3Ra"
      },
      "outputs": [],
      "source": [
        "embeddings, labels = extract_embeddings(referencia_dataset, model, dims = 512)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels)[0]"
      ],
      "metadata": {
        "id": "deifED0gJPeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# n_closest_images: (str), (int) ---> list\n",
        "# Funcion que recibe la ruta de una imagen y de manera opcional un numero entero\"n\" (por defecto 5), que escribe 3 listas y entrega 1:\n",
        "# Near_list: lista que contiene las n distancias mas cortas con respecto a la imagen entregada\n",
        "# List_labels: lista que contiene las etiquetas correspondientes a las \"n\" imagenes con distancias mas cortas. Esta lista es entregada por la funcion.\n",
        "# Label_ubication_list: lista que entrega la posicion de las \"n\" imagenes mas cercanas con respecto a su etiqueta.\n",
        "\n",
        "def n_closest_images(image, n=5):\n",
        "  img = Image.open(image).convert('RGB')\n",
        "  img = trans(img)\n",
        "  img = img.cuda()\n",
        "  emb_img = vgg_model(img.unsqueeze(0))\n",
        "  embedding_img = emb_img.data.cpu().numpy()\n",
        "  list_dist, list_labels, neat_list, label_ubication_list = [], [], [], []\n",
        "  for i in range(embeddings.shape[0]):\n",
        "    emb2 = embeddings[i,:]\n",
        "    dist = np.sum((emb2 - embedding_img)**2)\n",
        "    list_dist.append(dist)\n",
        "  neat_list[:] = list_dist\n",
        "  neat_list.sort()\n",
        "  for i in range(n):\n",
        "    position = list_dist.index(neat_list[i])\n",
        "    label_ubication = position - labels.index(labels[position])\n",
        "    label_ubication_list.append(label_ubication)\n",
        "    list_labels.append(labels[position])\n",
        "  #print (neat_list[:n], list_labels, label_ubication_list)\n",
        "  return list_labels"
      ],
      "metadata": {
        "id": "Yh3JngKpNTZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def closest_image_after_rotation(image):\n",
        "  img = Image.open(image).convert('RGB')\n",
        "  flip = transforms.RandomHorizontalFlip(p=1)\n",
        "  img = flip(img)\n",
        "  img = trans(img)\n",
        "  img = img.cuda()\n",
        "  emb_img = vgg_model(img.unsqueeze(0))\n",
        "  embedding_img = emb_img.data.cpu().numpy()\n",
        "  list_dist, list_labels, neat_list, label_ubication_list = [], [], [], []\n",
        "  for i in range(embeddings.shape[0]):\n",
        "    emb2 = embeddings[i,:]\n",
        "    dist = np.sum((emb2 - embedding_img)**2)\n",
        "    list_dist.append(dist)\n",
        "  neat_list[:] = list_dist\n",
        "  neat_list.sort()\n",
        "  for i in range(1):\n",
        "    position = list_dist.index(neat_list[i])\n",
        "    label_ubication = position - labels.index(labels[position])\n",
        "    label_ubication_list.append(label_ubication)\n",
        "    list_labels.append(labels[position])\n",
        "  return list_labels"
      ],
      "metadata": {
        "id": "-cjaZ4gYPSiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def percentage_check_from_valid(dataset):\n",
        "  Right1 = 0\n",
        "  Right3 = 0\n",
        "  Right5 = 0\n",
        "  for i in range(len(dataset.data)):\n",
        "    img = dataset.data[i]\n",
        "    label= n_closest_images(img, n=10)\n",
        "    if label[0] == dataset.targets[i]:\n",
        "      Right1 += 1\n",
        "    if dataset.targets[i] in label[:3]:\n",
        "      Right3 += 1\n",
        "    if dataset.targets[i] in label[:5]:\n",
        "      Right5 += 1\n",
        "  Total = len(dataset.targets)\n",
        "  Percentage1 = 100.0*Right1/Total\n",
        "  Percentage3 = 100.0*Right3/Total\n",
        "  Percentage5 = 100.0*Right5/Total\n",
        "  print (\"% \" + str(Percentage1) +\" de las imagenes fueron clasificadas correctamente en top 1.\")\n",
        "  print (\"% \" + str(Percentage3) +\" de las imagenes fueron clasificadas correctamente en top 3.\")\n",
        "  print (\"% \" + str(Percentage5) +\" de las imagenes fueron clasificadas correctamente en top 5.\")"
      ],
      "metadata": {
        "id": "QTE5SgfONbM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "percentage_check_from_valid(test_dataset)"
      ],
      "metadata": {
        "id": "ioUmuOeFN6BQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def percentage_check(dataset):\n",
        "  Right = 0\n",
        "  for i in range(len(dataset.data)):\n",
        "    img = dataset.data[i]\n",
        "    label= closest_image_after_rotation(img)\n",
        "    if label[0] == dataset.targets[i]:\n",
        "      Right += 1\n",
        "  Total = len(dataset.targets)\n",
        "  Percentage = 100.0*Right/Total\n",
        "  print (\"% \" + str(Percentage) +\" de las imagenes fueron clasificadas correctamente.\")"
      ],
      "metadata": {
        "id": "FKmZ0NvtPMp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "percentage_check(test_dataset)"
      ],
      "metadata": {
        "id": "8cI0enOTPOd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset.class_to_idx"
      ],
      "metadata": {
        "id": "OeNBF-SLCOAp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}