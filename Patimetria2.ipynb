{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IsugSfCY_zE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d69d89b-acf1-44c1-e62c-654f7b73ad31"
      },
      "source": [
        "from google.colab import drive  # Se importa el drive donde estan todos los .py y las imagenes utilizadas, esta celda debe ser modificada en caso de que se quiera probar el codigo en otro equipo.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/sensxciones/Proyecto_Humedales.git"
      ],
      "metadata": {
        "id": "UzDNBvRJVX2z",
        "outputId": "ba994709-3004-419d-bc9f-5a25500445c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Proyecto_Humedales'...\n",
            "remote: Enumerating objects: 1407, done.\u001b[K\n",
            "remote: Counting objects: 100% (80/80), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 1407 (delta 28), reused 72 (delta 24), pack-reused 1327\u001b[K\n",
            "Receiving objects: 100% (1407/1407), 106.02 MiB | 38.98 MiB/s, done.\n",
            "Resolving deltas: 100% (32/32), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cd Proyecto_Humedales && git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmyyEyY-IqTp",
        "outputId": "28910a88-724c-49d7-c761-b1a31491e272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB-oh40GYmf8"
      },
      "source": [
        "# Se importar todos los modulos y funciones necesarios\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import sys\n",
        "sys.path.append('Proyecto_Humedales')\n",
        "\n",
        "#La siguiente importacion es de un codigo diseñado para el proyecto patimetria:\n",
        "from duckies_dataset import DuckieDataset, Rescale\n",
        "#Los siguientes modulos son versiones modificadas de .py de terceros adapatados para utilizar en el proyecto patimetria.\n",
        "# Los modulos originales se encuentran en el siguiente git: https://github.com/adambielski/siamese-triplet\n",
        "from networks import VGGEmbeddingNet, EmbeddingNet, TripletNet\n",
        "from trainer import fit, train_epoch, test_epoch\n",
        "from datasets import TripletMNIST\n",
        "from losses import TripletLoss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-clKeEwY1Ot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5f203ce-1bae-4f44-815a-dfb95f649437"
      },
      "source": [
        "# Se cargan 2 modelos a utilizar.\n",
        "vgg_model = VGGEmbeddingNet()\n",
        "# emb_net = EmbeddingNet()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:03<00:00, 144MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLOX2DaaY-_Z"
      },
      "source": [
        "# Se define una transformacion que convierte las imagenes a tensores de tamaño [224, 224]\n",
        "trans = transforms.Compose([Rescale(224),\n",
        "                            transforms.ToTensor()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld4nhSBNZmy8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "11f4f032-e5a9-4930-882b-bd71dd10e4ea"
      },
      "source": [
        "# Se definen los datasets de entrenamiento y de testeo.\n",
        "train_dataset = DuckieDataset(\"/content/drive/MyDrive/bird-dataset/train\",train = False, transform= trans)\n",
        "test_dataset = DuckieDataset(\"/content/drive/MyDrive/bird-dataset/test\",train = False, transform= trans)\n",
        "valid_dataset = DuckieDataset(\"/content/drive/MyDrive/bird-dataset/valid\",train = False, transform= trans)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-63848247607c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Se definen los datasets de entrenamiento y de testeo.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDuckieDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/bird-dataset/train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDuckieDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/bird-dataset/test\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalid_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDuckieDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/bird-dataset/valid\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Proyecto_Humedales/duckies_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDuckieDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m       \u001b[0mpatos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m       \u001b[0mpatos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/bird-dataset/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn2gkk-saRZq"
      },
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "%matplotlib inline\n",
        "# Set up data loaders\n",
        "\n",
        "triplet_train_dataset = TripletMNIST(train_dataset) # Returns triplets of images\n",
        "triplet_test_dataset = TripletMNIST(test_dataset)\n",
        "batch_size = 32\n",
        "kwargs = {'num_workers': 2, 'pin_memory': True} if cuda else {}\n",
        "triplet_train_loader = torch.utils.data.DataLoader(triplet_train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
        "triplet_test_loader = torch.utils.data.DataLoader(triplet_test_dataset, batch_size=batch_size, shuffle=False, **kwargs)\n",
        "\n",
        "# Set up the network and training parameters\n",
        "\n",
        "margin = 1.\n",
        "# embedding_net = EmbeddingNet()\n",
        "model = TripletNet(vgg_model)\n",
        "if cuda:\n",
        "    model.cuda()\n",
        "loss_fn = TripletLoss(margin)\n",
        "lr = 1e-3\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
        "n_epochs = 10\n",
        "log_interval = 500"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk7ukB4ga3RO"
      },
      "source": [
        "fit(triplet_train_loader, triplet_test_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval) #Se empieza a entrenar la red."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resume(model, filename):\n",
        "    if cuda:\n",
        "        model.load_state_dict(torch.load(filename))\n",
        "    else:\n",
        "        model.load_state_dict(torch.load(filename, map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "id": "rMfRzeJuq_6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),'/content/drive/MyDrive/bird-dataset/epoch-10.pth')"
      ],
      "metadata": {
        "id": "Or64lWvRaOwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cargado = TripletNet(vgg_model)\n",
        "if cuda:\n",
        "    model_cargado.cuda()\n",
        "\n",
        "resume(model_cargado, '/content/drive/MyDrive/bird-dataset/epoch-10.pth')"
      ],
      "metadata": {
        "id": "j5c4uxY7rCT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OF26aefvTNlk"
      },
      "source": [
        "# Define functions to extract embeddings using diferent datasets\n",
        "def extract_embeddings(dataset, model, dims = 1024, opt = None):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        embeddings = np.zeros((len(dataset), dims))\n",
        "        labels = list()\n",
        "        for k, it_ in enumerate(dataset):\n",
        "            images = it_[0].unsqueeze_(0)\n",
        "            images = images.cuda()\n",
        "            target = it_[1]\n",
        "            if opt is None:\n",
        "                aux = model.get_embedding(images).data.cpu().numpy()\n",
        "            else:\n",
        "                aux = model.get_embedding(images, opt).data.cpu().numpy()\n",
        "            embeddings[k] = aux.reshape(1, dims)\n",
        "            labels.append(target)\n",
        "    return embeddings, labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGORG9c1Twos"
      },
      "source": [
        "embeddings, labels = extract_embeddings(train_dataset, vgg_model, dims = 512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_dataset.data)"
      ],
      "metadata": {
        "id": "24lu46kXwrdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels)"
      ],
      "metadata": {
        "id": "5dmLaN5Yvbax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUfuE4B2pnlI"
      },
      "source": [
        "# n_closest_images: (str), (int) ---> list\n",
        "# Funcion que recibe la ruta de una imagen y de manera opcional un numero entero\"n\" (por defecto 5), que escribe 3 listas y entrega 1:\n",
        "# Near_list: lista que contiene las n distancias mas cortas con respecto a la imagen entregada\n",
        "# List_labels: lista que contiene las etiquetas correspondientes a las \"n\" imagenes con distancias mas cortas. Esta lista es entregada por la funcion.\n",
        "# Label_ubication_list: lista que entrega la posicion de las \"n\" imagenes mas cercanas con respecto a su etiqueta.\n",
        "\n",
        "def n_closest_images(image, n=5):\n",
        "  img = Image.open(image).convert('RGB')\n",
        "  img = trans(img)\n",
        "  img = img.cuda()\n",
        "  emb_img = vgg_model(img.unsqueeze(0))\n",
        "  embedding_img = emb_img.data.cpu().numpy()\n",
        "  list_dist, list_labels, neat_list, label_ubication_list = [], [], [], []\n",
        "  for i in range(embeddings.shape[0]):\n",
        "    emb2 = embeddings[i,:]\n",
        "    dist = np.sum((emb2 - embedding_img)**2)\n",
        "    list_dist.append(dist)\n",
        "  neat_list[:] = list_dist\n",
        "  neat_list.sort()\n",
        "  for i in range(n):\n",
        "    position = list_dist.index(neat_list[i])\n",
        "    label_ubication = position - labels.index(labels[position])\n",
        "    label_ubication_list.append(label_ubication)\n",
        "    list_labels.append(labels[position])\n",
        "  #print (neat_list[:n], list_labels, label_ubication_list)\n",
        "  return list_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYZvv4tkMwgC"
      },
      "source": [
        "n_closest_images(\"/content/drive/MyDrive/bird-dataset/test/ABBOTTS BABBLER/1.jpg\")[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLrMbPxjb5fr"
      },
      "source": [
        "# closest_image_after_rotation: (str) ---> list\n",
        "# Funcion que recibe la ruta de una imagen, escribe 3 numeros y entrega 1:\n",
        "# neat_list[:1]: Corresponde a la distancia mas corta entre la imagen entregada y una del dataset\n",
        "# list_labels: Corresponde a la lista con las etiquetas de las imagenes del dataset, ordenadas desde las imagenes mas cercanas hasta las mas alejadas con respecto a la imagen entregada.\n",
        "# esta lista es entregada por la funcion.\n",
        "# Label_ubication_list: lista que entrega la posicion de las imagenes con respecto a su etiqueta. (Nota: si en la etiqueta tiene \"n\" imagenes, 0 representa la primera imagen y\n",
        "# \"k\" representa la \"k+1\"-esima imagen)\"\n",
        "def closest_image_after_rotation(image):\n",
        "  img = Image.open(image).convert('RGB')\n",
        "  flip = transforms.RandomHorizontalFlip(p=1)\n",
        "  img = flip(img)\n",
        "  img = trans(img)\n",
        "  img = img.cuda()\n",
        "  emb_img = vgg_model(img.unsqueeze(0))\n",
        "  embedding_img = emb_img.data.cpu().numpy()\n",
        "  list_dist, list_labels, neat_list, label_ubication_list = [], [], [], []\n",
        "  for i in range(embeddings.shape[0]):\n",
        "    emb2 = embeddings[i,:]\n",
        "    dist = np.sum((emb2 - embedding_img)**2)\n",
        "    list_dist.append(dist)\n",
        "  neat_list[:] = list_dist\n",
        "  neat_list.sort()\n",
        "  for i in range(1):\n",
        "    position = list_dist.index(neat_list[i])\n",
        "    label_ubication = position - labels.index(labels[position])\n",
        "    label_ubication_list.append(label_ubication)\n",
        "    list_labels.append(labels[position])\n",
        "  return list_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ2vTN9wLlwv"
      },
      "source": [
        "# percentage_check (dataset) ---> ()\n",
        "# Funcion que recibe un dataset y rota las imagenes del mismo para luego pasarlas por la red y verificar cuantas imagenes son clasificadas correctamente en su etiqueta.\n",
        "# El resultado es escrito como un porcentaje\n",
        "def percentage_check(dataset):\n",
        "  Right = 0\n",
        "  for i in range(len(dataset.data)):\n",
        "    img = dataset.data[i]\n",
        "    label= closest_image_after_rotation(img)\n",
        "    if label[0] == dataset.targets[i]:\n",
        "      Right += 1\n",
        "  Total = len(dataset.targets)\n",
        "  Percentage = 100.0*Right/Total\n",
        "  print (\"% \" + str(Percentage) +\" de las imagenes fueron clasificadas correctamente.\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def percentage_check_from_valid(dataset):\n",
        "  Right1 = 0\n",
        "  Right3 = 0\n",
        "  Right5 = 0\n",
        "  for i in range(len(dataset.data)):\n",
        "    img = dataset.data[i]\n",
        "    label= n_closest_images(img, n=10)\n",
        "    if label[0] == dataset.targets[i]:\n",
        "      Right1 += 1\n",
        "    if dataset.targets[i] in label[:3]:\n",
        "      Right3 += 1\n",
        "    if dataset.targets[i] in label[:5]:\n",
        "      Right5 += 1\n",
        "  Total = len(dataset.targets)\n",
        "  Percentage1 = 100.0*Right1/Total\n",
        "  Percentage3 = 100.0*Right3/Total\n",
        "  Percentage5 = 100.0*Right5/Total\n",
        "  print (\"% \" + str(Percentage1) +\" de las imagenes fueron clasificadas correctamente en top 1.\")\n",
        "  print (\"% \" + str(Percentage3) +\" de las imagenes fueron clasificadas correctamente en top 3.\")\n",
        "  print (\"% \" + str(Percentage5) +\" de las imagenes fueron clasificadas correctamente en top 5.\")"
      ],
      "metadata": {
        "id": "Qu_YSeATc7f5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "percentage_check_from_valid(valid_dataset)"
      ],
      "metadata": {
        "id": "meY7d2KedHew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtNi2lfKRodR"
      },
      "source": [
        "percentage_check(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKvbggd1htPG"
      },
      "source": [
        "test_dataset.class_to_idx"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}