# -*- coding: utf-8 -*-
"""Patimetria2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15VH0vjpwV4DUXxyNJf5gpgx7QNSxoPbC
"""

from google.colab import drive  # Se importa el drive donde estan todos los .py y las imagenes utilizadas, esta celda debe ser modificada en caso de que se quiera probar el codigo en otro equipo.
drive.mount('/content/drive')

! git clone https://github.com/sensxciones/Proyecto_Humedales.git

! cd Proyecto_Humedales && git pull

# Se importar todos los modulos y funciones necesarios
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import torch
from torch.optim import lr_scheduler
import torch.optim as optim
from torch.autograd import Variable
from torchvision import models, transforms
from PIL import Image
import sys
sys.path.append('Proyecto_Humedales')

#La siguiente importacion es de un codigo diseñado para el proyecto patimetria:
from duckies_dataset import DuckieDataset, Rescale
#Los siguientes modulos son versiones modificadas de .py de terceros adapatados para utilizar en el proyecto patimetria.
# Los modulos originales se encuentran en el siguiente git: https://github.com/adambielski/siamese-triplet
from networks import VGGEmbeddingNet, EmbeddingNet, TripletNet
from trainer import fit, train_epoch, test_epoch
from datasets import TripletMNIST
from losses import TripletLoss

# Se cargan 2 modelos a utilizar.
vgg_model = VGGEmbeddingNet()
# emb_net = EmbeddingNet()

# Se define una transformacion que convierte las imagenes a tensores de tamaño [224, 224]
trans = transforms.Compose([Rescale(224),
                            transforms.ToTensor()])

# Se definen los datasets de entrenamiento y de testeo.
train_dataset = DuckieDataset("/content/drive/MyDrive/bird-dataset/train",train = False, transform= trans)
test_dataset = DuckieDataset("/content/drive/MyDrive/bird-dataset/test",train = False, transform= trans)
valid_dataset = DuckieDataset("/content/drive/MyDrive/bird-dataset/valid",train = False, transform= trans)

# Commented out IPython magic to ensure Python compatibility.
cuda = torch.cuda.is_available()
# %matplotlib inline
# Set up data loaders

triplet_train_dataset = TripletMNIST(train_dataset) # Returns triplets of images
triplet_test_dataset = TripletMNIST(test_dataset)
batch_size = 32
kwargs = {'num_workers': 2, 'pin_memory': True} if cuda else {}
triplet_train_loader = torch.utils.data.DataLoader(triplet_train_dataset, batch_size=batch_size, shuffle=True, **kwargs)
triplet_test_loader = torch.utils.data.DataLoader(triplet_test_dataset, batch_size=batch_size, shuffle=False, **kwargs)

# Set up the network and training parameters

margin = 1.
# embedding_net = EmbeddingNet()
model = TripletNet(vgg_model)
if cuda:
    model.cuda()
loss_fn = TripletLoss(margin)
lr = 1e-3
optimizer = optim.Adam(model.parameters(), lr=lr)
scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)
n_epochs = 10
log_interval = 500

fit(triplet_train_loader, triplet_test_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval) #Se empieza a entrenar la red.

def resume(model, filename):
    if cuda:
        model.load_state_dict(torch.load(filename))
    else:
        model.load_state_dict(torch.load(filename, map_location=torch.device('cpu')))

torch.save(model.state_dict(),'/content/drive/MyDrive/bird-dataset/epoch-10.pth')

model_cargado = TripletNet(vgg_model)
if cuda:
    model_cargado.cuda()

resume(model_cargado, '/content/drive/MyDrive/bird-dataset/epoch-10.pth')

# Define functions to extract embeddings using diferent datasets
def extract_embeddings(dataset, model, dims = 1024, opt = None):
    with torch.no_grad():
        model.eval()
        embeddings = np.zeros((len(dataset), dims))
        labels = list()
        for k, it_ in enumerate(dataset):
            images = it_[0].unsqueeze_(0)
            images = images.cuda()
            target = it_[1]
            if opt is None:
                aux = model.get_embedding(images).data.cpu().numpy()
            else:
                aux = model.get_embedding(images, opt).data.cpu().numpy()
            embeddings[k] = aux.reshape(1, dims)
            labels.append(target)
    return embeddings, labels

embeddings, labels = extract_embeddings(train_dataset, vgg_model, dims = 512)

len(test_dataset.data)

print(labels)

# n_closest_images: (str), (int) ---> list
# Funcion que recibe la ruta de una imagen y de manera opcional un numero entero"n" (por defecto 5), que escribe 3 listas y entrega 1:
# Near_list: lista que contiene las n distancias mas cortas con respecto a la imagen entregada
# List_labels: lista que contiene las etiquetas correspondientes a las "n" imagenes con distancias mas cortas. Esta lista es entregada por la funcion.
# Label_ubication_list: lista que entrega la posicion de las "n" imagenes mas cercanas con respecto a su etiqueta.

def n_closest_images(image, n=5):
  img = Image.open(image).convert('RGB')
  img = trans(img)
  img = img.cuda()
  emb_img = vgg_model(img.unsqueeze(0))
  embedding_img = emb_img.data.cpu().numpy()
  list_dist, list_labels, neat_list, label_ubication_list = [], [], [], []
  for i in range(embeddings.shape[0]):
    emb2 = embeddings[i,:]
    dist = np.sum((emb2 - embedding_img)**2)
    list_dist.append(dist)
  neat_list[:] = list_dist
  neat_list.sort()
  for i in range(n):
    position = list_dist.index(neat_list[i])
    label_ubication = position - labels.index(labels[position])
    label_ubication_list.append(label_ubication)
    list_labels.append(labels[position])
  #print (neat_list[:n], list_labels, label_ubication_list)
  return list_labels

n_closest_images("/content/drive/MyDrive/bird-dataset/test/ABBOTTS BABBLER/1.jpg")[0]

# closest_image_after_rotation: (str) ---> list
# Funcion que recibe la ruta de una imagen, escribe 3 numeros y entrega 1:
# neat_list[:1]: Corresponde a la distancia mas corta entre la imagen entregada y una del dataset
# list_labels: Corresponde a la lista con las etiquetas de las imagenes del dataset, ordenadas desde las imagenes mas cercanas hasta las mas alejadas con respecto a la imagen entregada.
# esta lista es entregada por la funcion.
# Label_ubication_list: lista que entrega la posicion de las imagenes con respecto a su etiqueta. (Nota: si en la etiqueta tiene "n" imagenes, 0 representa la primera imagen y
# "k" representa la "k+1"-esima imagen)"
def closest_image_after_rotation(image):
  img = Image.open(image).convert('RGB')
  flip = transforms.RandomHorizontalFlip(p=1)
  img = flip(img)
  img = trans(img)
  img = img.cuda()
  emb_img = vgg_model(img.unsqueeze(0))
  embedding_img = emb_img.data.cpu().numpy()
  list_dist, list_labels, neat_list, label_ubication_list = [], [], [], []
  for i in range(embeddings.shape[0]):
    emb2 = embeddings[i,:]
    dist = np.sum((emb2 - embedding_img)**2)
    list_dist.append(dist)
  neat_list[:] = list_dist
  neat_list.sort()
  for i in range(1):
    position = list_dist.index(neat_list[i])
    label_ubication = position - labels.index(labels[position])
    label_ubication_list.append(label_ubication)
    list_labels.append(labels[position])
  return list_labels

# percentage_check (dataset) ---> ()
# Funcion que recibe un dataset y rota las imagenes del mismo para luego pasarlas por la red y verificar cuantas imagenes son clasificadas correctamente en su etiqueta.
# El resultado es escrito como un porcentaje
def percentage_check(dataset):
  Right = 0
  for i in range(len(dataset.data)):
    img = dataset.data[i]
    label= closest_image_after_rotation(img)
    if label[0] == dataset.targets[i]:
      Right += 1
  Total = len(dataset.targets)
  Percentage = 100.0*Right/Total
  print ("% " + str(Percentage) +" de las imagenes fueron clasificadas correctamente.")

def percentage_check_from_valid(dataset):
  Right1 = 0
  Right3 = 0
  Right5 = 0
  for i in range(len(dataset.data)):
    img = dataset.data[i]
    label= n_closest_images(img, n=10)
    if label[0] == dataset.targets[i]:
      Right1 += 1
    if dataset.targets[i] in label[:3]:
      Right3 += 1
    if dataset.targets[i] in label[:5]:
      Right5 += 1
  Total = len(dataset.targets)
  Percentage1 = 100.0*Right1/Total
  Percentage3 = 100.0*Right3/Total
  Percentage5 = 100.0*Right5/Total
  print ("% " + str(Percentage1) +" de las imagenes fueron clasificadas correctamente en top 1.")
  print ("% " + str(Percentage3) +" de las imagenes fueron clasificadas correctamente en top 3.")
  print ("% " + str(Percentage5) +" de las imagenes fueron clasificadas correctamente en top 5.")

percentage_check_from_valid(valid_dataset)

percentage_check(test_dataset)

test_dataset.class_to_idx